{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLu6PvFISsY9xxCZX8AeUs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daliaezzat/ASOC_paper_code/blob/main/Phase_3_and_Phase_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjM2BFQDdpgz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "if (not tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
        "    print('Please install tensorflow 2.0 to run this notebook')\n",
        "print('Tensorflow version: ',tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn4BdKa3drDu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_probability as tfp\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "\n",
        "print(\"TFP Version\", tfp.__version__)\n",
        "print(\"TF  Version\",tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8bB7hXTdtCl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwO82TohYpLm"
      },
      "outputs": [],
      "source": [
        "!pip install PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZDNDdWJYsa5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2VB_-WxYvkD"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CERpNnP2Y488"
      },
      "outputs": [],
      "source": [
        "download = drive.CreateFile({'id': '1cA_rOXord2kQgzyxCNGfJi4CYOdDvG7F'})\n",
        "download.GetContentFile('breast_cancer.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXwNFIf1Y6bA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import io\n",
        "data = zipfile.ZipFile('breast_cancer.zip', 'r')\n",
        "data.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGxOYzQAZEOj"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/ratio_IDC3_breasr_cancer/train'\n",
        "validation_dir = '/content/ratio_IDC3_breasr_cancer/validation'\n",
        "test_dir = '/content/ratio_IDC3_breasr_cancer/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ulsNS0tIJit"
      },
      "outputs": [],
      "source": [
        "train_batch_size=32\n",
        "validation_batch_size=32\n",
        "image_size=280\n",
        "\n",
        "#----------------------------------------------- data preprocessing ---------------------------------------\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale = 1./255.,\n",
        "                                 rotation_range = 10,\n",
        "                                 width_shift_range = 0.2,\n",
        "                                 height_shift_range = 0.2,\n",
        "                                 shear_range = 0.3,\n",
        "                                 zoom_range = 0.25,\n",
        "                                 horizontal_flip = True,\n",
        "                                fill_mode='nearest')\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,\n",
        "                                                  target_size=(image_size,image_size),\n",
        "                                                  batch_size=train_batch_size,\n",
        "                                                  class_mode='categorical')\n",
        "validation_generator=test_datagen.flow_from_directory(validation_dir,\n",
        "                                                      target_size=(image_size,image_size),\n",
        "                                                      batch_size=validation_batch_size,\n",
        "                                                      shuffle=True,\n",
        "                                                      class_mode='categorical')\n",
        "\n",
        "\n",
        "#----------------------------------------------model------------------------------------------------------\n",
        "from tensorflow.keras import layers,optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import ResNet101V2\n",
        "conv_base = ResNet101V2(weights='imagenet',include_top=False,input_shape=(image_size,image_size, 3))\n",
        "conv_base.summary()\n",
        "\n",
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "conv_base.trainable=False\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dropout(0.263))\n",
        "model.add(layers.Dense(2,activation='softmax'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=1e-5)\n",
        "checkpointer = ModelCheckpoint(filepath='pretrained.weights.best.hdf5',monitor='val_accuracy', verbose = 1, save_best_only=True)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "model.compile(optimizer=optimizers.legacy.Adam(learning_rate=2e-5),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se1crcR3y1dG"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "import numpy as np\n",
        "train_classes=train_generator.classes\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_classes),\n",
        "                                        y = train_classes\n",
        "                                     )\n",
        "class_weights = dict(zip(np.unique(train_classes), class_weights)),\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou69RWE3yC5l"
      },
      "outputs": [],
      "source": [
        "history=model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
        "                    epochs=50,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples/train_generator.batch_size,\n",
        "                    verbose=1,\n",
        "                    class_weight=class_weights,\n",
        "                    callbacks=[checkpointer,early,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc8U27oNbKh6"
      },
      "outputs": [],
      "source": [
        "for layer in conv_base.layers:\n",
        "     layer.training = False\n",
        "     if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "         layer._per_input_updates = {}\n",
        "     elif isinstance(layer, tf.keras.layers.Dropout):\n",
        "         layer._per_input_updates = {}\n",
        "\n",
        "for layer in conv_base.layers[:-8]:\n",
        "    layer.trainable=False\n",
        "\n",
        "for layer in conv_base.layers[-8:]:\n",
        "     layer.trainable=True\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='pretrained.weights.best.hdf5',monitor='val_accuracy', verbose = 1, save_best_only=True)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=1e-7)\n",
        "model.compile(optimizer=optimizers.legacy.Adam(learning_rate=1e-6),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                     steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
        "                     epochs=50,\n",
        "                     validation_data=validation_generator,\n",
        "                     validation_steps=validation_generator.samples/train_generator.batch_size,\n",
        "                     verbose=1,\n",
        "                     class_weight=class_weights,\n",
        "                     callbacks=[checkpointer,early,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDZH2DDibWk2"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "model_mc_pred = K.function([model.input, K.learning_phase()], [model.output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fFc7mH6h7kq"
      },
      "outputs": [],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=4163,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtqogbimZpmB"
      },
      "outputs": [],
      "source": [
        "labels=np.array([\"0\",\"1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqjmJhKRyZar"
      },
      "outputs": [],
      "source": [
        "# Store the data in X_train, y_train variables by iterating over the batches\n",
        "batch_size=8\n",
        "test_generator.reset()\n",
        "x_test, y_test = next(test_generator)\n",
        "for i in tqdm(range(int(len(test_generator) / batch_size) - 1)): #1st batch is already fetched before the for loop.\n",
        "  img, label = next(test_generator)\n",
        "  x_test = np.append(x_test, img, axis = 0)\n",
        "  y_test = np.append(y_test, label, axis = 0)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIkeygni5Ips"
      },
      "outputs": [],
      "source": [
        "#no dropout at test time\n",
        "for i in range(0,5):\n",
        "  print(model_mc_pred([x_test[0:1],0])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3Gnp8u45UkH"
      },
      "outputs": [],
      "source": [
        "#dropout at test time\n",
        "for i in range(0,5):\n",
        "  print(model_mc_pred([x_test[0:1],1])[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout at test time\n",
        "for i in range(0,5):\n",
        "  print(model_mc_pred([x_test[800:801],1])[0])"
      ],
      "metadata": {
        "id": "NQnXqWZwTVWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_mc=np.zeros((len(x_test),2))\n",
        "pred_max_p_mc=np.zeros((len(x_test)))\n",
        "pred_std_mc=np.zeros((len(x_test)))\n",
        "entropy_mc = np.zeros((len(x_test)))\n",
        "\n",
        "for i in tqdm(range(0,len(x_test))):\n",
        "  multi_img=np.tile(x_test[i],(50,1,1,1))\n",
        "  preds=model_mc_pred([multi_img,1])\n",
        "  pred_mc[i]= np.mean(preds,axis=1)\n",
        "  pred_max_p_mc[i]=np.argmax(np.mean(preds,axis=1))#mean over n runs of every proba class\n",
        "  pred_std_mc[i]= np.sqrt(np.sum(np.var(preds, axis=1)))\n",
        "  entropy_mc[i] = -np.sum( pred_mc[i] * np.log2(pred_mc[i] + 1E-14)) #Numerical Stability\n",
        "pred_labels_mc=np.array([labels[np.argmax(pred_mc[i])] for i in range(0,len(pred_mc))])\n",
        "pred_mc_mean_max_p=np.array([pred_mc[i][np.argmax(pred_mc[i])] for i in range(0,len(pred_mc))])\n",
        "nll_mc=-np.log(pred_mc_mean_max_p)"
      ],
      "metadata": {
        "id": "DzHW20PHN1nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entropy_mc"
      ],
      "metadata": {
        "id": "u4cVfCO3O8RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(entropy_mc) / len(entropy_mc)"
      ],
      "metadata": {
        "id": "eD7FzJwcRnDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_std_mc"
      ],
      "metadata": {
        "id": "UzYgWDVLR7Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(pred_std_mc) / len(pred_std_mc)"
      ],
      "metadata": {
        "id": "zvUI1tXaR84c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6kNY5XHN0oH"
      },
      "outputs": [],
      "source": [
        "true_labels= test_generator.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZy6ktOpZAK9"
      },
      "outputs": [],
      "source": [
        "l = dict((v,k) for k,v in test_generator.class_indices.items())\n",
        "true_labels = np.array([l[k] for k in true_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgoYEjPjZU2R"
      },
      "outputs": [],
      "source": [
        "print(true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbq_XdZxVFX0"
      },
      "outputs": [],
      "source": [
        "print(pred_labels_mc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIeLbNl-AVGa"
      },
      "outputs": [],
      "source": [
        "test_acc_all_mc=np.average(true_labels==pred_labels_mc)\n",
        "test_acc_all_mc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRAFGIrIhnBx"
      },
      "source": [
        "correct_indices = np.nonzero(pred_labels_mc == true_labels)[0]\n",
        "incorrect_indices = np.nonzero(pred_labels_mc != true_labels)[0]\n",
        "print(len(correct_indices),\" classified correctly\")\n",
        "print(len(incorrect_indices),\" classified incorrectly\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adapt figure size to accomodate 18 subplots\n",
        "plt.rcParams['figure.figsize'] = (7,14)\n",
        "figure_evaluation = plt.figure()\n",
        "# plot incorrect predictions\n",
        "for i, incorrect in enumerate(incorrect_indices[:6]):\n",
        "    plt.subplot(6,3,i+10)\n",
        "    plt.imshow(x_test[incorrect].reshape(280,280,3), cmap='gray', interpolation='none')\n",
        "    plt.title(\n",
        "      \"Predicted {}, Truth: {}, entropy (uncertainty): {}, prob: {}, , std: {}\".format(pred_labels_mc[incorrect],\n",
        "                                                        true_labels[incorrect],\n",
        "                                                        entropy_mc[incorrect],\n",
        "                                                        pred_mc[incorrect],\n",
        "                                                        pred_std_mc[incorrect]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "# figure_evaluation"
      ],
      "metadata": {
        "id": "ZuFXUzuSVoR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adapt figure size to accomodate 18 subplots\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (7,14)\n",
        "\n",
        "figure_evaluation = plt.figure()\n",
        "\n",
        "# plot incorrect predictions\n",
        "for i, correct in enumerate(correct_indices[:6]):\n",
        "    plt.subplot(6,3,i+10)\n",
        "    plt.imshow(x_test[correct].reshape(280,280,3), cmap='gray', interpolation='none')\n",
        "    plt.title(\n",
        "      \"Predicted {}, Truth: {}, entropy (uncertainty): {}, prob: {}, , std: {}\".format(pred_labels_mc[correct],\n",
        "                                                        true_labels[correct],\n",
        "                                                        entropy_mc[correct],\n",
        "                                                        pred_mc[correct],\n",
        "                                                        pred_std_mc[correct]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "# figure_evaluation"
      ],
      "metadata": {
        "id": "MqVkUuC5dWou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCdX8Qblgfdt"
      },
      "outputs": [],
      "source": [
        "#Confution Matrix and Classification Report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(true_labels,pred_labels_mc))\n",
        "print('Classification Report')\n",
        "target_names = ['0', '1']\n",
        "print(classification_report(true_labels,pred_labels_mc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbA7xScxsr6x"
      },
      "outputs": [],
      "source": [
        "errors = np.where(pred_labels_mc != true_labels)[0]\n",
        "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true=[int(x) for x in true_labels]\n",
        "y_pred=[int(x) for x in pred_labels_mc]"
      ],
      "metadata": {
        "id": "5kdu0bwFSkJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "fpr, tpr, tresholds = metrics.roc_curve(y_true, y_pred)"
      ],
      "metadata": {
        "id": "zNE8bjvRSlEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (5,5)\n",
        "figure_evaluation = plt.figure()\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.plot(fpr, tpr, 'b', label = 'ROC curve(area= %0.2f)' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WCPvw-uQSp7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}